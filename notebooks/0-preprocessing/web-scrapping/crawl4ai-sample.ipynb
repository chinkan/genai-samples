{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting crawl4ai\n",
      "  Using cached Crawl4AI-0.4.247-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting aiosqlite~=0.20 (from crawl4ai)\n",
      "  Using cached aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting lxml~=5.3 (from crawl4ai)\n",
      "  Using cached lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting litellm>=1.53.1 (from crawl4ai)\n",
      "  Downloading litellm-1.59.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting numpy<3,>=1.26.0 (from crawl4ai)\n",
      "  Downloading numpy-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pillow~=10.4 (from crawl4ai)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting playwright>=1.49.0 (from crawl4ai)\n",
      "  Using cached playwright-1.49.1-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv~=1.0 (from crawl4ai)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting requests~=2.26 (from crawl4ai)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting beautifulsoup4~=4.12 (from crawl4ai)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting tf-playwright-stealth>=1.1.0 (from crawl4ai)\n",
      "  Using cached tf_playwright_stealth-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting xxhash~=3.4 (from crawl4ai)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting rank-bm25~=0.2 (from crawl4ai)\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting aiofiles>=24.1.0 (from crawl4ai)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting colorama~=0.4 (from crawl4ai)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting snowballstemmer~=2.2 (from crawl4ai)\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pydantic>=2.10 (from crawl4ai)\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pyOpenSSL>=24.3.0 (from crawl4ai)\n",
      "  Using cached pyOpenSSL-25.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: psutil>=6.1.1 in /home/kan/workspaces/poc/genai-samples/.venv/lib/python3.12/site-packages (from crawl4ai) (6.1.1)\n",
      "Collecting nltk>=3.9.1 (from crawl4ai)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing_extensions>=4.0 (from aiosqlite~=0.20->crawl4ai)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4~=4.12->crawl4ai)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting aiohttp (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting click (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<0.28.0,>=0.23.0 (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting jinja2<4.0.0,>=3.1.2 (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting openai>=1.55.3 (from litellm>=1.53.1->crawl4ai)\n",
      "  Downloading openai-1.59.8-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken>=0.7.0 (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tokenizers (from litellm>=1.53.1->crawl4ai)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting joblib (from nltk>=3.9.1->crawl4ai)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.9.1->crawl4ai)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from nltk>=3.9.1->crawl4ai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting greenlet==3.1.1 (from playwright>=1.49.0->crawl4ai)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyee==12.0.0 (from playwright>=1.49.0->crawl4ai)\n",
      "  Using cached pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.10->crawl4ai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.10->crawl4ai)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting cryptography<45,>=41.0.5 (from pyOpenSSL>=24.3.0->crawl4ai)\n",
      "  Using cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests~=2.26->crawl4ai)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests~=2.26->crawl4ai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests~=2.26->crawl4ai)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests~=2.26->crawl4ai)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting fake-http-header<0.4.0,>=0.3.5 (from tf-playwright-stealth>=1.1.0->crawl4ai)\n",
      "  Using cached fake_http_header-0.3.5-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pytest-mockito<0.0.5,>=0.0.4 (from tf-playwright-stealth>=1.1.0->crawl4ai)\n",
      "  Using cached pytest_mockito-0.0.4-py3-none-any.whl\n",
      "Collecting cffi>=1.12 (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting anyio (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sniffio (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)\n",
      "  Downloading referencing-0.36.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.55.3->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.55.3->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached jiter-0.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pytest>=3 (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai)\n",
      "  Using cached pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting mockito>=1.0.6 (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai)\n",
      "  Using cached mockito-1.5.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/kan/workspaces/poc/genai-samples/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting iniconfig (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Using cached Crawl4AI-0.4.247-py3-none-any.whl (166 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading litellm-1.59.0-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading numpy-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached playwright-1.49.1-py3-none-manylinux1_x86_64.whl (44.2 MB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "Using cached pyee-12.0.0-py3-none-any.whl (14 kB)\n",
      "Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached pyOpenSSL-25.0.0-py3-none-any.whl (56 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Using cached tf_playwright_stealth-1.1.0-py3-none-any.whl (33 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
      "Using cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "Using cached fake_http_header-0.3.5-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading openai-1.59.8-py3-none-any.whl (455 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Using cached huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached jiter-0.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mockito-1.5.3-py3-none-any.whl (30 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Using cached pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Downloading referencing-0.36.1-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: snowballstemmer, zipp, xxhash, urllib3, typing_extensions, tqdm, soupsieve, sniffio, rpds-py, regex, pyyaml, python-dotenv, pycparser, propcache, pluggy, pillow, numpy, multidict, mockito, MarkupSafe, lxml, joblib, jiter, iniconfig, idna, h11, greenlet, fsspec, frozenlist, filelock, fake-http-header, distro, colorama, click, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, aiofiles, yarl, requests, referencing, rank-bm25, pytest, pyee, pydantic-core, nltk, jinja2, importlib-metadata, httpcore, cffi, beautifulsoup4, anyio, aiosqlite, aiosignal, tiktoken, pytest-mockito, pydantic, playwright, jsonschema-specifications, huggingface-hub, httpx, cryptography, aiohttp, tokenizers, tf-playwright-stealth, pyOpenSSL, openai, jsonschema, litellm, crawl4ai\n",
      "Successfully installed MarkupSafe-3.0.2 aiofiles-24.1.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 aiosqlite-0.20.0 annotated-types-0.7.0 anyio-4.8.0 attrs-24.3.0 beautifulsoup4-4.12.3 certifi-2024.12.14 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 colorama-0.4.6 crawl4ai-0.4.247 cryptography-44.0.0 distro-1.9.0 fake-http-header-0.3.5 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.12.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 huggingface-hub-0.27.1 idna-3.10 importlib-metadata-8.5.0 iniconfig-2.0.0 jinja2-3.1.5 jiter-0.8.2 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 litellm-1.59.0 lxml-5.3.0 mockito-1.5.3 multidict-6.1.0 nltk-3.9.1 numpy-2.2.2 openai-1.59.8 pillow-10.4.0 playwright-1.49.1 pluggy-1.5.0 propcache-0.2.1 pyOpenSSL-25.0.0 pycparser-2.22 pydantic-2.10.5 pydantic-core-2.27.2 pyee-12.0.0 pytest-8.3.4 pytest-mockito-0.0.4 python-dotenv-1.0.1 pyyaml-6.0.2 rank-bm25-0.2.2 referencing-0.36.1 regex-2024.11.6 requests-2.32.3 rpds-py-0.22.3 sniffio-1.3.1 snowballstemmer-2.2.0 soupsieve-2.6 tf-playwright-stealth-1.1.0 tiktoken-0.8.0 tokenizers-0.21.0 tqdm-4.67.1 typing_extensions-4.12.2 urllib3-2.3.0 xxhash-3.5.0 yarl-1.18.3 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the package\n",
    "%pip install -U crawl4ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The following commands require sudo/admin privileges to run. As Jupyter notebooks cannot input passwords, you may need to run these commands in a terminal outside of the notebook environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run post-installation setup\n",
    "!crawl4ai-setup\n",
    "\n",
    "# Verify your installation\n",
    "!crawl4ai-doctor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above commands, you should see output similar to the following:\n",
    "\n",
    "1. Post-installation setup:\n",
    "   ```\n",
    "   [COMPLETE] ● Database initialization completed successfully.\n",
    "   [COMPLETE] ● Post-installation setup completed!\n",
    "   ```\n",
    "\n",
    "2. Installation verification:\n",
    "   ```\n",
    "   [COMPLETE] ● https://crawl4ai.com... | Status: True | Total: 17.10s\n",
    "   [COMPLETE] ● ✅ Crawling test passed!\n",
    "   ```\n",
    "\n",
    "These messages indicate that the setup was successful and the installation is working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/kan/workspaces/poc/genai-samples/.venv/lib/python3.12/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kan/workspaces/poc/genai-samples/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/kan/workspaces/poc/genai-samples/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install pandas for easy view results in notebook\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Using crawl4ai without LLM\n",
    "\n",
    "The following code demonstrates how to use crawl4ai to crawl a website and extract links without using any language model:\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from crawl4ai import AsyncWebCrawler\n",
    "import pandas as pd\n",
    "\n",
    "async def crawl_website():\n",
    "    async with AsyncWebCrawler(verbose=True, headless=True) as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=\"https://www1.hkej.com/features/topic/tag/%E8%99%9B%E5%B9%A3%E5%8B%95%E6%85%8B\",\n",
    "            bypass_cache=False,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Get all internal links from the website\n",
    "        df = pd.DataFrame(result.links[\"internal\"])\n",
    "        display(df)\n",
    "\n",
    "asyncio.run(crawl_website())\n",
    "```\n",
    "\n",
    "This example crawls the specified URL and displays all internal links found on the page using a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from crawl4ai import AsyncWebCrawler\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www1.hkej.com/features/topic/tag/%E8%99%9B... | Status: True | Time: 0.01s\n",
      "[COMPLETE] ● https://www1.hkej.com/features/topic/tag/%E8%99%9B... | Status: True | Total: 0.02s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>base_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://subscribe.hkej.com</td>\n",
       "      <td>訂閱 / 續訂</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://subscribe.hkej.com/register</td>\n",
       "      <td>註冊</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://subscribe.hkej.com/member/login?forwar...</td>\n",
       "      <td>登入</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www2.hkej.com/landing/index</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www2.hkej.com/weather/weather.php?loca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>https://www2.hkej.com/info/privacy</td>\n",
       "      <td>私隱條款</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>https://www2.hkej.com/info/disclaimer</td>\n",
       "      <td>免責聲明</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>https://www.hkej.com/ratecard/html/index.html</td>\n",
       "      <td>廣告查詢</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>https://www2.hkej.com/info/jobs</td>\n",
       "      <td>加入信報</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>https://www2.hkej.com/info/contactus</td>\n",
       "      <td>聯絡信報</td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  href     text title  \\\n",
       "0                           https://subscribe.hkej.com  訂閱 / 續訂         \n",
       "1                  https://subscribe.hkej.com/register       註冊         \n",
       "2    https://subscribe.hkej.com/member/login?forwar...       登入         \n",
       "3                  https://www2.hkej.com/landing/index                  \n",
       "4    https://www2.hkej.com/weather/weather.php?loca...                  \n",
       "..                                                 ...      ...   ...   \n",
       "120                 https://www2.hkej.com/info/privacy     私隱條款         \n",
       "121              https://www2.hkej.com/info/disclaimer     免責聲明         \n",
       "122      https://www.hkej.com/ratecard/html/index.html     廣告查詢         \n",
       "123                    https://www2.hkej.com/info/jobs     加入信報         \n",
       "124               https://www2.hkej.com/info/contactus     聯絡信報         \n",
       "\n",
       "    base_domain  \n",
       "0      hkej.com  \n",
       "1      hkej.com  \n",
       "2      hkej.com  \n",
       "3      hkej.com  \n",
       "4      hkej.com  \n",
       "..          ...  \n",
       "120    hkej.com  \n",
       "121    hkej.com  \n",
       "122    hkej.com  \n",
       "123    hkej.com  \n",
       "124    hkej.com  \n",
       "\n",
       "[125 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>href</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>base_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>hkej.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 href text title base_domain\n",
       "30  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "31  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "32  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "33  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "34  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "35  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "36  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "37  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "38  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "39  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "40  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "41  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "42  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "43  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "44  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "45  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "46  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "47  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "48  https://www1.hkej.com/features/article?q=%23%E...               hkej.com\n",
       "49  https://www1.hkej.com/features/article?q=%23%E...               hkej.com"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try to Grapping news from hkej website\n",
    "\n",
    "async with AsyncWebCrawler(verbose=True,headless=True) as crawler:\n",
    "    result = await crawler.arun(\n",
    "        url=\"https://www1.hkej.com/features/topic/tag/%E8%99%9B%E5%B9%A3%E5%8B%95%E6%85%8B\",\n",
    "        bypass_cache=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Example 1: Get all links from the website\n",
    "    df = pd.DataFrame(result.links[\"internal\"])\n",
    "    display(df)\n",
    "    \n",
    "    # Example 2: Get all news links from the website\n",
    "    df_filtered = df[df['href'].str.contains('article', case=False, na=False)]\n",
    "    display(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Using crawl4ai with LLM and Pydantic Schema\n",
    "\n",
    "This example demonstrates how to use crawl4ai with a language model (LLM) and a Pydantic schema to extract specific information from a website.\n",
    "\n",
    "```python\n",
    "from crawl4ai import AsyncWebCrawler, LLMExtractionStrategy, CrawlerRunConfig, CacheMode\n",
    "\n",
    "async def crawl_with_llm():\n",
    "    async with AsyncWebCrawler(verbose=True, headless=True) as crawler:\n",
    "        result = await crawler.arun(\n",
    "            url=\"https://www1.hkej.com/features/topic/tag/%E8%99%9B%E5%B9%A3%E5%8B%95%E6%85%8B\",\n",
    "            config=crawler_config,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Display the extracted data\n",
    "        for item in result.extracted_data:\n",
    "            print(json.dumps(item, indent=2, ensure_ascii=False))\n",
    "\n",
    "asyncio.run(crawl_with_llm())\n",
    "```\n",
    "\n",
    "This code uses the `LLMExtractionStrategy` with a custom Pydantic schema to extract specific information (title, image URL, article URL, and date) from news articles. The LLM is guided by a simple prompt to focus on these details during the extraction process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.247\n",
      "[FETCH]... ↓ https://www1.hkej.com/features/topic/tag/%E8%99%9B... | Status: True | Time: 6.65s\n",
      "[SCRAPE].. ◆ Processed https://www1.hkej.com/features/topic/tag/%E8%99%9B... | Time: 102ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:45:18 - LiteLLM:INFO: utils.py:2820 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = azure\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = azure\n",
      "INFO:httpx:HTTP Request: POST https://azugenaia201.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-08-01-preview \"HTTP/1.1 200 OK\"\n",
      "17:45:41 - LiteLLM:INFO: utils.py:952 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXTRACT]. ■ Completed for https://www1.hkej.com/features/topic/tag/%E8%99%9B... | Time: 23.121848894050345s\n",
      "[COMPLETE] ● https://www1.hkej.com/features/topic/tag/%E8%99%9B... | Status: True | Total: 29.90s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>image</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$TRUMP幣熱炒 存利益衝突</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2025/01/20...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2025年1月20日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HashKey Exchange去年交易量升85% 料今年達收支平衡</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2025/01/15...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2025年1月15日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z世代寧買比特幣更勝置業</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2025/01/15...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2025年1月15日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>歐股靠穩 比特幣失守9.2萬美元</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2025/01/10...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2025年1月10日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>【ETF特搜】比特幣重上10萬美元 相關ETF升逾2%</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2025/01/07...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2025年1月7日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>馬斯克X賬號改名 迷因幣爆炒</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2025/01/03...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2025年1月3日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>比特幣獲唱好今年衝上20萬美元</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2025/01/02...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2025年1月2日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>聯儲局官員戴利:加密貨幣並非黃金</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/31...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月31日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>星洲年批13加密幣牌照 遠超香港</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/27...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月27日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>比特幣瘋炒 2024最癲交易</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/24...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月24日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>【ETF特搜】虛幣續受壓 比特幣插逾4% 以太幣ETF瀉7%</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/20...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月20日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>風險胃納降 比特幣挫逾半成失守10萬美元關</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/19...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月19日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>【ETF特搜】比特幣ETF插逾4% 比特幣價回落至10萬美元邊</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/19...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月19日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>比特幣創新高 升穿10.5萬美元</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/16...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月16日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>貝萊德建議投資者考慮配置比特幣最多2%</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/13...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月13日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>特朗普:將對加密貨幣採取某些重大行動</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/13...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月13日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>富途料恒指明年見24200點 比特幣挑戰12.2萬美元</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/12...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月12日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>微軟股東否決投資比特幣 原因原來是?</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/11...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月11日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>比特幣頂位急回7%後喘穩</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/07...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月7日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>比特幣狂飆 新華社:美國須以負責任態度對待金融監管</td>\n",
       "      <td>https://static.hkej.com/hkej/images/2024/12/06...</td>\n",
       "      <td>https://www1.hkej.com/features/article?q=%23%E...</td>\n",
       "      <td>2024年12月6日</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0                      $TRUMP幣熱炒 存利益衝突   \n",
       "1   HashKey Exchange去年交易量升85% 料今年達收支平衡   \n",
       "2                         Z世代寧買比特幣更勝置業   \n",
       "3                     歐股靠穩 比特幣失守9.2萬美元   \n",
       "4          【ETF特搜】比特幣重上10萬美元 相關ETF升逾2%   \n",
       "5                       馬斯克X賬號改名 迷因幣爆炒   \n",
       "6                      比特幣獲唱好今年衝上20萬美元   \n",
       "7                     聯儲局官員戴利:加密貨幣並非黃金   \n",
       "8                     星洲年批13加密幣牌照 遠超香港   \n",
       "9                       比特幣瘋炒 2024最癲交易   \n",
       "10      【ETF特搜】虛幣續受壓 比特幣插逾4% 以太幣ETF瀉7%   \n",
       "11               風險胃納降 比特幣挫逾半成失守10萬美元關   \n",
       "12     【ETF特搜】比特幣ETF插逾4% 比特幣價回落至10萬美元邊   \n",
       "13                    比特幣創新高 升穿10.5萬美元   \n",
       "14                 貝萊德建議投資者考慮配置比特幣最多2%   \n",
       "15                  特朗普:將對加密貨幣採取某些重大行動   \n",
       "16         富途料恒指明年見24200點 比特幣挑戰12.2萬美元   \n",
       "17                  微軟股東否決投資比特幣 原因原來是?   \n",
       "18                        比特幣頂位急回7%後喘穩   \n",
       "19           比特幣狂飆 新華社:美國須以負責任態度對待金融監管   \n",
       "\n",
       "                                                image  \\\n",
       "0   https://static.hkej.com/hkej/images/2025/01/20...   \n",
       "1   https://static.hkej.com/hkej/images/2025/01/15...   \n",
       "2   https://static.hkej.com/hkej/images/2025/01/15...   \n",
       "3   https://static.hkej.com/hkej/images/2025/01/10...   \n",
       "4   https://static.hkej.com/hkej/images/2025/01/07...   \n",
       "5   https://static.hkej.com/hkej/images/2025/01/03...   \n",
       "6   https://static.hkej.com/hkej/images/2025/01/02...   \n",
       "7   https://static.hkej.com/hkej/images/2024/12/31...   \n",
       "8   https://static.hkej.com/hkej/images/2024/12/27...   \n",
       "9   https://static.hkej.com/hkej/images/2024/12/24...   \n",
       "10  https://static.hkej.com/hkej/images/2024/12/20...   \n",
       "11  https://static.hkej.com/hkej/images/2024/12/19...   \n",
       "12  https://static.hkej.com/hkej/images/2024/12/19...   \n",
       "13  https://static.hkej.com/hkej/images/2024/12/16...   \n",
       "14  https://static.hkej.com/hkej/images/2024/12/13...   \n",
       "15  https://static.hkej.com/hkej/images/2024/12/13...   \n",
       "16  https://static.hkej.com/hkej/images/2024/12/12...   \n",
       "17  https://static.hkej.com/hkej/images/2024/12/11...   \n",
       "18  https://static.hkej.com/hkej/images/2024/12/07...   \n",
       "19  https://static.hkej.com/hkej/images/2024/12/06...   \n",
       "\n",
       "                                                  url         date  error  \n",
       "0   https://www1.hkej.com/features/article?q=%23%E...   2025年1月20日  False  \n",
       "1   https://www1.hkej.com/features/article?q=%23%E...   2025年1月15日  False  \n",
       "2   https://www1.hkej.com/features/article?q=%23%E...   2025年1月15日  False  \n",
       "3   https://www1.hkej.com/features/article?q=%23%E...   2025年1月10日  False  \n",
       "4   https://www1.hkej.com/features/article?q=%23%E...    2025年1月7日  False  \n",
       "5   https://www1.hkej.com/features/article?q=%23%E...    2025年1月3日  False  \n",
       "6   https://www1.hkej.com/features/article?q=%23%E...    2025年1月2日  False  \n",
       "7   https://www1.hkej.com/features/article?q=%23%E...  2024年12月31日  False  \n",
       "8   https://www1.hkej.com/features/article?q=%23%E...  2024年12月27日  False  \n",
       "9   https://www1.hkej.com/features/article?q=%23%E...  2024年12月24日  False  \n",
       "10  https://www1.hkej.com/features/article?q=%23%E...  2024年12月20日  False  \n",
       "11  https://www1.hkej.com/features/article?q=%23%E...  2024年12月19日  False  \n",
       "12  https://www1.hkej.com/features/article?q=%23%E...  2024年12月19日  False  \n",
       "13  https://www1.hkej.com/features/article?q=%23%E...  2024年12月16日  False  \n",
       "14  https://www1.hkej.com/features/article?q=%23%E...  2024年12月13日  False  \n",
       "15  https://www1.hkej.com/features/article?q=%23%E...  2024年12月13日  False  \n",
       "16  https://www1.hkej.com/features/article?q=%23%E...  2024年12月12日  False  \n",
       "17  https://www1.hkej.com/features/article?q=%23%E...  2024年12月11日  False  \n",
       "18  https://www1.hkej.com/features/article?q=%23%E...   2024年12月7日  False  \n",
       "19  https://www1.hkej.com/features/article?q=%23%E...   2024年12月6日  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Token Usage Summary ===\n",
      "Type                   Count\n",
      "------------------------------\n",
      "Completion             2,878\n",
      "Prompt                12,430\n",
      "Total                 15,308\n",
      "\n",
      "=== Usage History ===\n",
      "Request #    Completion       Prompt        Total\n",
      "------------------------------------------------\n",
      "1                 2,878       12,430       15,308\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from crawl4ai import LLMExtractionStrategy, CrawlerRunConfig, CacheMode\n",
    "\n",
    "class OpenAIModelFee(BaseModel):\n",
    "    title: str = Field(..., description=\"News title.\")\n",
    "    image: str = Field(..., description=\"Url of the news thumbnail.\")\n",
    "    url: str = Field(..., description=\"Url of the news.\")\n",
    "    date: str = Field(..., description=\"Date of the news.\")\n",
    "\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "provider = f\"azure/{deployment_name}\"\n",
    "api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_token = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "extra_args = {\"temperature\": 0.7}\n",
    "\n",
    "llm_strategy = LLMExtractionStrategy(\n",
    "            api_base = api_base,\n",
    "            provider=provider,\n",
    "            api_token=api_token,\n",
    "            schema=OpenAIModelFee.model_json_schema(),\n",
    "            extraction_type=\"schema\",\n",
    "            instruction=\"\"\"From the crawled content, extract all the news title, image url, url and date.\"\"\",\n",
    "            extra_args=extra_args,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "crawler_config = CrawlerRunConfig(\n",
    "        cache_mode=CacheMode.BYPASS,\n",
    "        word_count_threshold=1,\n",
    "        page_timeout=80000,\n",
    "        extraction_strategy=llm_strategy,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "async with AsyncWebCrawler() as crawler:\n",
    "    result = await crawler.arun(\n",
    "        url=\"https://www1.hkej.com/features/topic/tag/%E8%99%9B%E5%B9%A3%E5%8B%95%E6%85%8B\",\n",
    "        bypass_cache=False,\n",
    "        verbose=False,\n",
    "        config=crawler_config\n",
    "    )\n",
    "    # The JSON output is stored in 'extracted_content'\n",
    "    data = json.loads(result.extracted_content)\n",
    "    df = pd.DataFrame(data)\n",
    "    display(df)\n",
    "\n",
    "    llm_strategy.show_usage() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
